{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing with Spark and Hadoop"
      ],
      "metadata": {
        "id": "RY-A3c-y8reE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hadoop MapReduce Job"
      ],
      "metadata": {
        "id": "5uVUPtUnqxic"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKJW1RGrjkdu",
        "outputId": "dfbdd666-c05a-4228-c1fe-f968666e64eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender Frequency Count: defaultdict(<class 'int'>, {'Male': 2603096, 'Female': 2412641})\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "from collections import defaultdict\n",
        "# providing the dataset path\n",
        "data_path = \"/content/retailstore_5mn.csv\"\n",
        "# Reading the CSV file (simulating HDFS read)\n",
        "import pandas as pd\n",
        "df = pd.read_csv(data_path)\n",
        "# Simulating Hadoop MapReduce: Map function\n",
        "def mapper(df):\n",
        "    result = defaultdict(int)\n",
        "    for index, row in df.iterrows():\n",
        "        result[row['Gender']] += 1\n",
        "    return result\n",
        "# Simulating Hadoop MapReduce: Reduce function\n",
        "def reducer(mapped_data):\n",
        "    result = defaultdict(int)\n",
        "    for key, value in mapped_data.items():\n",
        "        result[key] += value\n",
        "    return result\n",
        "# Running the map function\n",
        "mapped_data = mapper(df)\n",
        "# Running the reduce function\n",
        "reduced_data = reducer(mapped_data)\n",
        "# Printing the final result\n",
        "print(\"Gender Frequency Count:\", reduced_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apache Spark Job (Using PySpark)"
      ],
      "metadata": {
        "id": "Q6HaHThpq5cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing and setting up PySpark\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg, count\n",
        "# Starting the Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"RetailStoreAnalytics\").getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKRFfwbAj0QG",
        "outputId": "ef78bf95-fb78-4323-a833-fa267a7c7b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.4)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "data_path = \"/content/retailstore_5mn.csv\"\n",
        "# Reading the dataset using Spark\n",
        "df_spark = spark.read.csv(data_path, header=True, inferSchema=True)\n",
        "# Showing the first few rows of the dataset\n",
        "df_spark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC8U0PwnrQ-W",
        "outputId": "b2867817-7bf5-4bf1-e37d-8166c74a6078"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+------+------+-------+\n",
            "|CustomerID|        Age|Salary|Gender|Country|\n",
            "+----------+-----------+------+------+-------+\n",
            "|         1|       18.0| 20000|  Male|Germany|\n",
            "|         2|       19.0| 22000|Female| France|\n",
            "|         3|       20.0| 24000|Female|England|\n",
            "|         4|       21.0|  2600|  Male|England|\n",
            "|         5|       22.0| 50000|  Male| France|\n",
            "|         6|       23.0| 35000|Female|England|\n",
            "|         7|       24.0|  4300|  Male|Germany|\n",
            "|         8|       25.0| 32000|Female| France|\n",
            "|         9|       35.0| 35000|  Male|Germany|\n",
            "|        10|       27.0| 37000|Female| France|\n",
            "|        11|       31.0| 25000|  Male|Germany|\n",
            "|        12|32.38181818| 27000|Female| France|\n",
            "|        13|33.76363636| 29000|Female|England|\n",
            "|        14|35.14545455|  7600|  Male|England|\n",
            "|        15|36.52727273| 55000|  Male| France|\n",
            "|        16|37.90909091| 40000|Female|England|\n",
            "|        17|39.29090909|  9300|  Male|Germany|\n",
            "|        18|40.67272727| 37000|Female| France|\n",
            "|        19|42.05454545| 40000|  Male|Germany|\n",
            "|        20|43.43636364| 42000|Female| France|\n",
            "+----------+-----------+------+------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Aggregation: Calculating the average salary by gender\n",
        "avg_salary = df_spark.groupBy(\"Gender\").agg(avg(\"Salary\").alias(\"Average_Salary\"))\n",
        "avg_salary.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-sa0VqbrZub",
        "outputId": "11335ee1-42b1-497a-ed5d-a21d038f5dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+\n",
            "|Gender|    Average_Salary|\n",
            "+------+------------------+\n",
            "|Female| 35388.00070130616|\n",
            "|  Male|35387.738139507725|\n",
            "+------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Filtering: Filtering rows where Salary is greater than 30,000\n",
        "high_salary_df = df_spark.filter(df_spark['Salary'] > 30000)\n",
        "high_salary_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk1klO2qriLT",
        "outputId": "b130d780-8d52-462a-858c-666357344e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+------+------+-------+\n",
            "|CustomerID|        Age|Salary|Gender|Country|\n",
            "+----------+-----------+------+------+-------+\n",
            "|         5|       22.0| 50000|  Male| France|\n",
            "|         6|       23.0| 35000|Female|England|\n",
            "|         8|       25.0| 32000|Female| France|\n",
            "|         9|       35.0| 35000|  Male|Germany|\n",
            "|        10|       27.0| 37000|Female| France|\n",
            "|        15|36.52727273| 55000|  Male| France|\n",
            "|        16|37.90909091| 40000|Female|England|\n",
            "|        18|40.67272727| 37000|Female| France|\n",
            "|        19|42.05454545| 40000|  Male|Germany|\n",
            "|        20|43.43636364| 42000|Female| France|\n",
            "|        22|       46.2| 32000|Female| France|\n",
            "|        23|47.58181818| 34000|Female| France|\n",
            "|        25|50.34545455| 60000|Female|Germany|\n",
            "|        26|51.72727273| 45000|Female|Germany|\n",
            "|        28|54.49090909| 42000|  Male|Germany|\n",
            "|        29|55.87272727| 45000|  Male|England|\n",
            "|        30|57.25454545| 47000|  Male|England|\n",
            "|        31|58.63636364| 35000|  Male|England|\n",
            "|        32|60.01818182| 37000|  Male|England|\n",
            "|        33|       61.4| 39000|  Male|England|\n",
            "+----------+-----------+------+------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploratory Data Analysis (EDA): Counting the number of people by country\n",
        "country_count = df_spark.groupBy(\"Country\").agg(count(\"CustomerID\").alias(\"Customer_Count\"))\n",
        "country_count.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcntmPTsrnmb",
        "outputId": "b3c3bce4-5560-485b-9759-d9aa5224c1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------+\n",
            "|Country|Customer_Count|\n",
            "+-------+--------------+\n",
            "|Germany|       1332307|\n",
            "| France|       1410671|\n",
            "|England|       2272759|\n",
            "+-------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stopping the Spark session when done\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "C1fkv8qnr0KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Analytics and Machine Learning"
      ],
      "metadata": {
        "id": "IXI-IB_o8u7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.sql.functions import col\n",
        "# Initializing the Spark session\n",
        "spark = SparkSession.builder.appName(\"GenderPrediction\").getOrCreate()"
      ],
      "metadata": {
        "id": "yEcfe4r6r5FS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "data_path = \"/content/retailstore_5mn.csv\"\n",
        "df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
        "# Showing the first few rows of the data\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELIUHubA88_y",
        "outputId": "1682eb48-a29c-4f0f-812b-0bc69a539c1f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+------+------+-------+\n",
            "|CustomerID| Age|Salary|Gender|Country|\n",
            "+----------+----+------+------+-------+\n",
            "|         1|18.0| 20000|  Male|Germany|\n",
            "|         2|19.0| 22000|Female| France|\n",
            "|         3|20.0| 24000|Female|England|\n",
            "|         4|21.0|  2600|  Male|England|\n",
            "|         5|22.0| 50000|  Male| France|\n",
            "+----------+----+------+------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Managing the missing values\n",
        "df = df.dropna()\n",
        "# Converting the 'Gender' column to the numeric\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"GenderIndex\")\n",
        "df = indexer.fit(df).transform(df)\n",
        "# Choosing significant features for the model\n",
        "features = [\"Age\", \"Salary\"]\n",
        "df = df.select(\"GenderIndex\", *features)\n",
        "# Developing the feature vector\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "df = assembler.transform(df)\n"
      ],
      "metadata": {
        "id": "f-YQ6qth9JYo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=1234)"
      ],
      "metadata": {
        "id": "INOJ7_Tg9X03"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the Logistic Regression model\n",
        "lr = LogisticRegression(labelCol=\"GenderIndex\", featuresCol=\"features\")\n",
        "# Training the model on the training data\n",
        "lr_model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "G3TUsG2m9eL_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the predictions on the test data\n",
        "predictions = lr_model.transform(test_data)\n",
        "# Evaluating the model utilizing the BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"GenderIndex\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Model Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEmomwwD9ji3",
        "outputId": "d53c3215-1533-4aa4-9767-c71fe64e9fd1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.49945660161104444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qf3rDDiU-HR9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}